{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7fceb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eddy\\AppData\\Local\\Temp\\ipykernel_32736\\794715721.py:133: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  signal_m = signal_series.resample('M').last()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== With VIX Filter ===\n",
      "Start                                  2013-01-02 00:00:00\n",
      "End                                    2025-09-30 00:00:00\n",
      "Period                                  3206 days 00:00:00\n",
      "Start Value                                      1000000.0\n",
      "End Value                                   3175778.916753\n",
      "Total Return [%]                                217.577892\n",
      "Benchmark Return [%]                            381.054944\n",
      "Max Gross Exposure [%]                               100.0\n",
      "Total Fees Paid                               34751.572498\n",
      "Max Drawdown [%]                                   32.8233\n",
      "Max Drawdown Duration                    306 days 00:00:00\n",
      "Total Trades                                          8422\n",
      "Total Closed Trades                                   8416\n",
      "Total Open Trades                                        6\n",
      "Open Trade PnL                               207124.505705\n",
      "Win Rate [%]                                       59.0423\n",
      "Best Trade [%]                                    97.16031\n",
      "Worst Trade [%]                                 -41.197512\n",
      "Avg Winning Trade [%]                            13.679696\n",
      "Avg Losing Trade [%]                             -6.299716\n",
      "Avg Winning Trade Duration    1389 days 11:38:07.220768768\n",
      "Avg Losing Trade Duration     1354 days 06:38:57.336814624\n",
      "Profit Factor                                     3.265494\n",
      "Expectancy                                      233.918062\n",
      "Sharpe Ratio                                      0.915529\n",
      "Calmar Ratio                                      0.428369\n",
      "Omega Ratio                                       1.164713\n",
      "Sortino Ratio                                     1.256011\n",
      "Name: group, dtype: object\n",
      "\n",
      "=== Baseline (No Filter) ===\n",
      "Start                                  2013-01-02 00:00:00\n",
      "End                                    2025-09-30 00:00:00\n",
      "Period                                  3206 days 00:00:00\n",
      "Start Value                                      1000000.0\n",
      "End Value                                   4026720.843464\n",
      "Total Return [%]                                302.672084\n",
      "Benchmark Return [%]                            381.054944\n",
      "Max Gross Exposure [%]                               100.0\n",
      "Total Fees Paid                               30752.890824\n",
      "Max Drawdown [%]                                   32.8233\n",
      "Max Drawdown Duration                    463 days 00:00:00\n",
      "Total Trades                                          8437\n",
      "Total Closed Trades                                   8431\n",
      "Total Open Trades                                        6\n",
      "Open Trade PnL                               478989.804785\n",
      "Win Rate [%]                                     59.945439\n",
      "Best Trade [%]                                  109.609889\n",
      "Worst Trade [%]                                 -39.490412\n",
      "Avg Winning Trade [%]                            16.688967\n",
      "Avg Losing Trade [%]                             -6.715324\n",
      "Avg Winning Trade Duration    1689 days 06:58:50.193905824\n",
      "Avg Losing Trade Duration     1532 days 17:43:54.172342320\n",
      "Profit Factor                                     4.009333\n",
      "Expectancy                                      302.186104\n",
      "Sharpe Ratio                                      0.973739\n",
      "Calmar Ratio                                       0.52357\n",
      "Omega Ratio                                       1.168295\n",
      "Sortino Ratio                                     1.354396\n",
      "Name: group, dtype: object\n",
      "\n",
      "Saved NAV series to 'taa_vix_filter_navs.csv'\n"
     ]
    }
   ],
   "source": [
    "# taa_vix_filter_vectorbt_corrected_v2.py\n",
    "# Replicates the \"Timing Leveraged Equity Exposure in a TAA Model\" overlay\n",
    "# using Bloomberg data (xbbg) and vectorbt (OSS), with robust index handling.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xbbg import blp\n",
    "import vectorbt as vbt\n",
    "\n",
    "# -------------------\n",
    "# Helpers\n",
    "# -------------------\n",
    "def extract_field(df, field='PX_LAST'):\n",
    "    \"\"\"Return a 2D DataFrame of the requested field with tickers as columns.\n",
    "    Works whether xbbg.bdh returned single-field (flat) or multi-field (MultiIndex) columns.\"\"\"\n",
    "    cols = df.columns\n",
    "    if isinstance(cols, pd.MultiIndex):\n",
    "        for lvl in range(cols.nlevels):\n",
    "            if field in cols.get_level_values(lvl):\n",
    "                out = df.xs(field, axis=1, level=lvl)\n",
    "                if isinstance(out, pd.Series):\n",
    "                    out = out.to_frame()\n",
    "                return out\n",
    "        raise KeyError(f\"Field {field!r} not found in MultiIndex columns: {cols.names}\")\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "def ensure_dtindex(obj):\n",
    "    \"\"\"Coerce Series/DataFrame index to tz-naive DatetimeIndex, sorted, drop unparseable.\"\"\"\n",
    "    if isinstance(obj, (pd.Series, pd.DataFrame)):\n",
    "        out = obj.copy()\n",
    "        out.index = pd.to_datetime(out.index, errors='coerce')\n",
    "        out = out[out.index.notna()]\n",
    "        try:\n",
    "            if getattr(out.index, 'tz', None) is not None:\n",
    "                out.index = out.index.tz_localize(None)\n",
    "        except Exception:\n",
    "            pass\n",
    "        return out.sort_index()\n",
    "    return obj\n",
    "\n",
    "def ann_vol(daily_ret, periods=252):\n",
    "    return daily_ret.std() * np.sqrt(periods)\n",
    "\n",
    "def vol_target_path(nav_series, target_vol=0.10, periods=252):\n",
    "    \"\"\"Post-hoc scale a NAV path to target annualized vol for comparability (reporting only).\"\"\"\n",
    "    nav_series = nav_series.dropna()\n",
    "    if len(nav_series) < 2:\n",
    "        return nav_series.copy()\n",
    "    ret = nav_series.pct_change().fillna(0.0)\n",
    "    current_vol = ann_vol(ret, periods=periods)\n",
    "    if current_vol == 0 or np.isnan(current_vol):\n",
    "        return nav_series.copy()\n",
    "    scale = target_vol / current_vol\n",
    "    scaled_ret = ret * scale\n",
    "    scaled_nav = (1 + scaled_ret).cumprod()\n",
    "    scaled_nav *= nav_series.iloc[0] / scaled_nav.iloc[0]\n",
    "    return scaled_nav\n",
    "\n",
    "# -------------------\n",
    "# Parameters\n",
    "# -------------------\n",
    "start = '2013-01-01'\n",
    "end   = '2025-09-30'           # article span\n",
    "fees  = 0.0005                 # 5 bps per trade\n",
    "use_cash_proxy = True          # False = assume 0% cash return\n",
    "cash_ticker = 'BIL US Equity'  # or 'SHV US Equity'\n",
    "fallback_weight = 0.30         # weight of the fallback sleeve\n",
    "robust = False                 # True -> 10/15/20-day voting logic\n",
    "\n",
    "# -------------------\n",
    "# Bloomberg tickers & data\n",
    "# -------------------\n",
    "px_tickers = [\n",
    "    'SPY US Equity','SPXL US Equity','TLT US Equity','GLD US Equity',\n",
    "    'DBC US Equity','UUP US Equity','BTAL US Equity'\n",
    "]\n",
    "if use_cash_proxy:\n",
    "    px_tickers = px_tickers + [cash_ticker]\n",
    "\n",
    "prices_raw = blp.bdh(tickers=px_tickers, flds='PX_LAST', start_date=start, end_date=end)\n",
    "prices = extract_field(prices_raw, 'PX_LAST')\n",
    "\n",
    "vix_raw = blp.bdh(tickers='VIX Index', flds='PX_LAST', start_date=start, end_date=end)\n",
    "vix = extract_field(vix_raw, 'PX_LAST').squeeze()\n",
    "vix.name = 'VIX'\n",
    "\n",
    "# Standardize column names\n",
    "rename_map = {\n",
    "    'SPY US Equity':'SPY',\n",
    "    'SPXL US Equity':'SPXL',\n",
    "    'TLT US Equity':'TLT',\n",
    "    'GLD US Equity':'GLD',\n",
    "    'DBC US Equity':'DBC',\n",
    "    'UUP US Equity':'UUP',\n",
    "    'BTAL US Equity':'BTAL',\n",
    "    'BIL US Equity':'BIL',\n",
    "    'SHV US Equity':'SHV'\n",
    "}\n",
    "prices = prices.rename(columns={k:v for k,v in rename_map.items() if k in prices.columns})\n",
    "cash_short = rename_map.get(cash_ticker, cash_ticker) if use_cash_proxy else None\n",
    "\n",
    "# Ensure datetime indices\n",
    "prices = ensure_dtindex(prices)\n",
    "vix    = ensure_dtindex(vix)\n",
    "\n",
    "# Join and clean\n",
    "data = ensure_dtindex(prices.join(vix, how='inner'))\n",
    "data = data.loc[~data.index.duplicated(keep='first')].dropna(how='all')\n",
    "\n",
    "# -------------------\n",
    "# Signal: RV vs VIX\n",
    "# -------------------\n",
    "ret_spy = data['SPY'].pct_change()\n",
    "\n",
    "def realized_vol(series, win):\n",
    "    return series.rolling(win).std() * np.sqrt(252)\n",
    "\n",
    "if robust:\n",
    "    wins = [10, 15, 20]\n",
    "    rv_df = pd.concat({w: realized_vol(ret_spy, w) for w in wins}, axis=1).dropna()\n",
    "    vix_aligned = data['VIX'].reindex(rv_df.index)\n",
    "    rv_gt_vix = (rv_df > (vix_aligned / 100).values.reshape(-1,1)).astype(int)\n",
    "    votes = rv_gt_vix.sum(axis=1)\n",
    "    spxl_alloc_frac = votes.map({0: 1.0, 1: 2/3, 2: 1/3, 3: 0.0})\n",
    "    signal_series = spxl_alloc_frac.astype(float)\n",
    "else:\n",
    "    rv20 = realized_vol(ret_spy, 20).dropna()\n",
    "    vix_aligned = data['VIX'].reindex(rv20.index)\n",
    "    signal_series = (rv20 < (vix_aligned / 100)).astype(float)\n",
    "\n",
    "signal_series = ensure_dtindex(signal_series).astype(float)\n",
    "signal_m = signal_series.resample('M').last()\n",
    "\n",
    "# -------------------\n",
    "# Fallback sleeve weights {SPXL, CASH}\n",
    "# -------------------\n",
    "weights_fallback = pd.DataFrame(index=signal_m.index, columns=['SPXL','CASH'], dtype=float)\n",
    "weights_fallback['SPXL'] = signal_m.values\n",
    "weights_fallback['CASH'] = 1.0 - weights_fallback['SPXL']\n",
    "\n",
    "# -------------------\n",
    "# Full portfolio weights (placeholder sleeves + fallback)\n",
    "# -------------------\n",
    "sleeves = ['TLT','GLD','DBC','UUP','BTAL']\n",
    "n_sleeves = len(sleeves)\n",
    "\n",
    "tradables = ['SPXL','TLT','GLD','DBC','UUP','BTAL']\n",
    "if use_cash_proxy:\n",
    "    tradables.append(cash_short)\n",
    "tradables = [c for c in tradables if c in data.columns]\n",
    "\n",
    "base_w = pd.DataFrame(0.0, index=weights_fallback.index, columns=tradables)\n",
    "\n",
    "# Equal-weight the non-fallback sleeves within (1 - fallback_weight)\n",
    "if n_sleeves > 0:\n",
    "    for s in sleeves:\n",
    "        if s in base_w.columns:\n",
    "            base_w[s] = (1 - fallback_weight) / n_sleeves\n",
    "\n",
    "# Split fallback between SPXL and Cash per the signal\n",
    "if 'SPXL' in base_w.columns:\n",
    "    base_w['SPXL'] = fallback_weight * weights_fallback['SPXL']\n",
    "if use_cash_proxy:\n",
    "    if cash_short not in base_w.columns:\n",
    "        raise ValueError(f\"Cash proxy '{cash_short}' missing from price matrix.\")\n",
    "    base_w[cash_short] = fallback_weight * weights_fallback['CASH']\n",
    "\n",
    "# Baseline (no VIX filter): fallback fully in SPXL\n",
    "base_w_nofilter = base_w.copy()\n",
    "if 'SPXL' in base_w_nofilter.columns:\n",
    "    base_w_nofilter['SPXL'] = fallback_weight * 1.0\n",
    "if use_cash_proxy and (cash_short in base_w_nofilter.columns):\n",
    "    base_w_nofilter[cash_short] = 0.0\n",
    "\n",
    "# -------------------\n",
    "# Reindex weights to daily & build price matrix\n",
    "# -------------------\n",
    "price_cols = [c for c in base_w.columns if c in data.columns]\n",
    "price_mat = data[price_cols].copy()\n",
    "\n",
    "w_filter_daily   = base_w.reindex(price_mat.index).ffill().fillna(0.0)\n",
    "w_nofilter_daily = base_w_nofilter.reindex(price_mat.index).ffill().fillna(0.0)\n",
    "\n",
    "# Sanity: ensure same columns & order\n",
    "w_filter_daily = w_filter_daily[price_mat.columns]\n",
    "w_nofilter_daily = w_nofilter_daily[price_mat.columns]\n",
    "\n",
    "# -------------------\n",
    "# VectorBT (OSS): use from_orders with targetpercent\n",
    "# -------------------\n",
    "pf_filter = vbt.Portfolio.from_orders(\n",
    "    close=price_mat,\n",
    "    size=w_filter_daily,              # target % weights\n",
    "    size_type='targetpercent',\n",
    "    fees=fees,\n",
    "    fixed_fees=0.0,\n",
    "    slippage=0.0,\n",
    "    cash_sharing=True,\n",
    "    init_cash=1_000_000,\n",
    "    freq='D'\n",
    ")\n",
    "\n",
    "pf_nofilter = vbt.Portfolio.from_orders(\n",
    "    close=price_mat,\n",
    "    size=w_nofilter_daily,\n",
    "    size_type='targetpercent',\n",
    "    fees=fees,\n",
    "    fixed_fees=0.0,\n",
    "    slippage=0.0,\n",
    "    cash_sharing=True,\n",
    "    init_cash=1_000_000,\n",
    "    freq='D'\n",
    ")\n",
    "\n",
    "# -------------------\n",
    "# Stats & 10% vol-scaled NAVs\n",
    "# -------------------\n",
    "print(\"=== With VIX Filter ===\")\n",
    "print(pf_filter.stats())\n",
    "print(\"\\n=== Baseline (No Filter) ===\")\n",
    "print(pf_nofilter.stats())\n",
    "\n",
    "nav_filter   = pf_filter.value()\n",
    "nav_nofilter = pf_nofilter.value()\n",
    "\n",
    "nav_filter_10 = vol_target_path(nav_filter, target_vol=0.10)\n",
    "nav_nofilt_10 = vol_target_path(nav_nofilter, target_vol=0.10)\n",
    "\n",
    "out = pd.DataFrame({\n",
    "    'NAV_Filter'     : nav_filter,\n",
    "    'NAV_NoFilter'   : nav_nofilter,\n",
    "    'NAV_Filter_10%' : nav_filter_10,\n",
    "    'NAV_NoFilt_10%' : nav_nofilt_10,\n",
    "}).dropna()\n",
    "out.to_csv('taa_vix_filter_navs.csv', index=True)\n",
    "\n",
    "print(\"\\nSaved NAV series to 'taa_vix_filter_navs.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55a3d3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== WITH VIX FILTER (raw) ===\n",
      "Start                 : 2013-01-02\n",
      "End                   : 2025-09-30\n",
      "CAGR                  :  0.0987\n",
      "AnnVol                :  0.1331\n",
      "Sharpe                :  0.7743\n",
      "Sortino               :  1.0712\n",
      "MaxDD                 : -31.54%\n",
      "DD_Peak               : 2020-02-19\n",
      "DD_Trough             : 2020-03-23\n",
      "DD_Recovery           : 2021-04-13\n",
      "DD_DurationDays       : 288\n",
      "Calmar                :  0.3130\n",
      "HitRate_Daily         :  0.5473\n",
      "Skew                  : -0.8358\n",
      "Kurtosis              :  29.9746\n",
      "N_Days                : 3205\n",
      "AvgMonthlyTurnover    :  0.0759\n",
      "\n",
      "=== BASELINE (raw) ===\n",
      "Start                 : 2013-01-02\n",
      "End                   : 2025-09-30\n",
      "CAGR                  :  0.1202\n",
      "AnnVol                :  0.1527\n",
      "Sharpe                :  0.8202\n",
      "Sortino               :  1.1479\n",
      "MaxDD                 : -31.54%\n",
      "DD_Peak               : 2020-02-19\n",
      "DD_Trough             : 2020-03-23\n",
      "DD_Recovery           : 2020-07-22\n",
      "DD_DurationDays       : 466\n",
      "Calmar                :  0.3811\n",
      "HitRate_Daily         :  0.5516\n",
      "Skew                  : -0.5372\n",
      "Kurtosis              :  18.3367\n",
      "N_Days                : 3205\n",
      "AvgMonthlyTurnover    :  0.0093\n",
      "\n",
      "=== WITH VIX FILTER (10% vol-scaled) ===\n",
      "Start                 : 2013-01-02\n",
      "End                   : 2025-09-30\n",
      "CAGR                  :  0.0751\n",
      "AnnVol                :  0.1000\n",
      "Sharpe                :  0.7743\n",
      "Sortino               :  1.0712\n",
      "MaxDD                 : -24.39%\n",
      "DD_Peak               : 2020-02-19\n",
      "DD_Trough             : 2020-03-23\n",
      "DD_Recovery           : 2021-04-08\n",
      "DD_DurationDays       : 285\n",
      "Calmar                :  0.3079\n",
      "HitRate_Daily         :  0.5473\n",
      "Skew                  : -0.8358\n",
      "Kurtosis              :  29.9746\n",
      "N_Days                : 3205\n",
      "\n",
      "=== BASELINE (10% vol-scaled) ===\n",
      "Start                 : 2013-01-02\n",
      "End                   : 2025-09-30\n",
      "CAGR                  :  0.0801\n",
      "AnnVol                :  0.1000\n",
      "Sharpe                :  0.8202\n",
      "Sortino               :  1.1479\n",
      "MaxDD                 : -21.50%\n",
      "DD_Peak               : 2020-02-19\n",
      "DD_Trough             : 2020-03-23\n",
      "DD_Recovery           : 2020-07-20\n",
      "DD_DurationDays       : 460\n",
      "Calmar                :  0.3723\n",
      "HitRate_Daily         :  0.5516\n",
      "Skew                  : -0.5372\n",
      "Kurtosis              :  18.3367\n",
      "N_Days                : 3205\n",
      "\n",
      "Saved NAV series -> exact_taa_vix_filter_navs.csv\n"
     ]
    }
   ],
   "source": [
    "# exact_taa_vix_filter_xbbg.py\n",
    "# Exact replication of \"Timing Leveraged Equity Exposure in a TAA Model\"\n",
    "# Only change: data source is Bloomberg via xbbg. All warnings suppressed.\n",
    "\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xbbg import blp\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# ========================\n",
    "# Citations / Rules source\n",
    "# ========================\n",
    "# - Monthly rebalance; use only info up to prior trading day; 5 bps per trade;\n",
    "#   fallback toggles SPXL<->Cash using RV(20d) vs VIX; other sleeves unchanged (TLT, GLD, DBC, UUP, BTAL); report at 10% vol.\n",
    "#   Source: user-provided PDF summary. :contentReference[oaicite:1]{index=1}\n",
    "\n",
    "# ========================\n",
    "# Parameters\n",
    "# ========================\n",
    "START = '2013-01-01'\n",
    "END   = '2025-09-30'\n",
    "FEES  = 0.0005          # 5 bps per trade :contentReference[oaicite:2]{index=2}\n",
    "ROBUST = False          # True -> 10/15/20 voting variant :contentReference[oaicite:3]{index=3}\n",
    "FALLBACK_WEIGHT = 0.30  # portion of portfolio allocated to fallback sleeve (your TAA uses its own; plug exact below)\n",
    "RF_ANNUAL = 0.0         # risk-free for Sharpe/Sortino reporting\n",
    "INIT_NAV = 1_000_000.0\n",
    "TARGET_VOL = 0.10       # for reporting-only scaling (not a trading rule) :contentReference[oaicite:4]{index=4}\n",
    "\n",
    "# ================\n",
    "# Helper functions\n",
    "# ================\n",
    "def extract_field(df, field='PX_LAST'):\n",
    "    cols = df.columns\n",
    "    if isinstance(cols, pd.MultiIndex):\n",
    "        for lvl in range(cols.nlevels):\n",
    "            if field in cols.get_level_values(lvl):\n",
    "                out = df.xs(field, axis=1, level=lvl)\n",
    "                return out if isinstance(out, pd.DataFrame) else out.to_frame()\n",
    "        raise KeyError(f\"{field} not found\")\n",
    "    return df\n",
    "\n",
    "def ensure_dtindex(obj):\n",
    "    if isinstance(obj, (pd.Series, pd.DataFrame)):\n",
    "        out = obj.copy()\n",
    "        out.index = pd.to_datetime(out.index, errors='coerce')\n",
    "        out = out[out.index.notna()].sort_index()\n",
    "        try:\n",
    "            if getattr(out.index, 'tz', None) is not None:\n",
    "                out.index = out.index.tz_localize(None)\n",
    "        except Exception:\n",
    "            pass\n",
    "        return out\n",
    "    return obj\n",
    "\n",
    "def realized_vol(dret, win):\n",
    "    # annualized realized volatility from daily returns\n",
    "    return dret.rolling(win).std() * np.sqrt(252)\n",
    "\n",
    "def compute_drawdowns(nav):\n",
    "    peak = nav.cummax()\n",
    "    dd = nav / peak - 1.0\n",
    "    max_dd = float(dd.min())\n",
    "    # duration\n",
    "    dur = 0; max_dur = 0\n",
    "    for v in dd.values:\n",
    "        if v < 0: \n",
    "            dur += 1; max_dur = max(max_dur, dur)\n",
    "        else:\n",
    "            dur = 0\n",
    "    # dates\n",
    "    trough_date = dd.idxmin()\n",
    "    pre_peak = nav.loc[:trough_date]\n",
    "    peak_date = pre_peak.idxmax()\n",
    "    recov_date = None\n",
    "    post = nav.loc[trough_date:]\n",
    "    if not post.empty:\n",
    "        cm = post.cummax()\n",
    "        x = cm[cm >= nav.loc[peak_date]]\n",
    "        recov_date = x.index[0] if len(x) else None\n",
    "    return max_dd, max_dur, dd, peak_date, trough_date, recov_date\n",
    "\n",
    "def annualize_return(nav, periods_per_year=252):\n",
    "    ret = nav.pct_change().dropna()\n",
    "    if ret.empty: return np.nan\n",
    "    total = nav.iloc[-1] / nav.iloc[0] - 1.0\n",
    "    years = len(ret) / periods_per_year\n",
    "    return (1 + total)**(1/years) - 1 if years > 0 else np.nan\n",
    "\n",
    "def ann_vol(daily_ret, periods=252):\n",
    "    return daily_ret.std(ddof=0) * np.sqrt(periods)\n",
    "\n",
    "def downside_dev(daily_ret, mar=0.0, periods=252):\n",
    "    dn = np.minimum(daily_ret - mar/periods, 0.0)\n",
    "    return np.sqrt((dn**2).mean()) * np.sqrt(periods)\n",
    "\n",
    "def stats_panel(nav, rf=0.0):\n",
    "    nav = nav.dropna()\n",
    "    ret = nav.pct_change().dropna()\n",
    "    if ret.empty:\n",
    "        return {}, pd.Series(dtype=float)\n",
    "    cagr = annualize_return(nav)\n",
    "    vol = ann_vol(ret)\n",
    "    sharpe = np.nan if vol == 0 else ((ret.mean()*252 - rf)/vol)\n",
    "    ddev = downside_dev(ret)\n",
    "    sortino = np.nan if ddev == 0 else ((ret.mean()*252 - rf)/ddev)\n",
    "    mdd, mdd_len, dd_series, dd_peak, dd_trough, dd_recov = compute_drawdowns(nav)\n",
    "    calmar = np.nan if mdd == 0 else cagr/abs(mdd)\n",
    "    hit_d = (ret > 0).mean()\n",
    "    mret = ret.resample('ME').apply(lambda x: (1+x).prod()-1)\n",
    "    yret = ret.resample('YE').apply(lambda x: (1+x).prod()-1)\n",
    "    worst_m = mret.min() if not mret.empty else np.nan\n",
    "    worst_y = yret.min() if not yret.empty else np.nan\n",
    "    return {\n",
    "        'Start'       : nav.index[0].date(),\n",
    "        'End'         : nav.index[-1].date(),\n",
    "        'CAGR'        : float(cagr),\n",
    "        'AnnVol'      : float(vol),\n",
    "        'Sharpe'      : float(sharpe),\n",
    "        'Sortino'     : float(sortino),\n",
    "        'MaxDD'       : float(mdd),\n",
    "        'DD_Peak'     : dd_peak.date() if dd_peak is not None else None,\n",
    "        'DD_Trough'   : dd_trough.date() if dd_trough is not None else None,\n",
    "        'DD_Recovery' : dd_recov.date() if dd_recov is not None else None,\n",
    "        'DD_DurationDays': int(mdd_len),\n",
    "        'Calmar'      : float(calmar),\n",
    "        'HitRate_Daily': float(hit_d),\n",
    "        'Skew'        : float(skew(ret, bias=False)) if len(ret) > 2 else np.nan,\n",
    "        'Kurtosis'    : float(kurtosis(ret, fisher=True, bias=False)) if len(ret) > 3 else np.nan,\n",
    "        'N_Days'      : int(len(ret))\n",
    "    }, dd_series\n",
    "\n",
    "def vol_target_path(nav, target_vol=0.10):\n",
    "    ret = nav.pct_change().fillna(0.0)\n",
    "    v = ann_vol(ret)\n",
    "    if v == 0 or np.isnan(v): return nav.copy()\n",
    "    scale = target_vol / v\n",
    "    scaled = (1 + ret*scale).cumprod()\n",
    "    scaled *= nav.iloc[0] / scaled.iloc[0]\n",
    "    return scaled\n",
    "\n",
    "# =======================\n",
    "# Load base TAA weights\n",
    "# =======================\n",
    "def load_base_taa_weights(me_index, sleeves):\n",
    "    \"\"\"\n",
    "    Return a DataFrame of monthly weights for the non-fallback sleeves\n",
    "    (columns = sleeves; index = true month-ends present in price data).\n",
    "    Rows should sum to 1.0 - FALLBACK_WEIGHT.\n",
    "    To exactly match your TAA model, replace this stub with a CSV reader that loads your historical weights.\n",
    "    Example CSV format:\n",
    "        date,TLT,GLD,DBC,UUP,BTAL\n",
    "        2013-01-31,0.10,0.05,0.10,0.15,0.30\n",
    "        ...\n",
    "    \"\"\"\n",
    "    # --- PLACEHOLDER: equal-weight within (1 - FALLBACK_WEIGHT) ---\n",
    "    w = pd.DataFrame(0.0, index=me_index, columns=sleeves)\n",
    "    if len(sleeves) > 0:\n",
    "        for s in sleeves:\n",
    "            w[s] = (1 - FALLBACK_WEIGHT) / len(sleeves)\n",
    "    return w\n",
    "\n",
    "# ===========\n",
    "# Data (BBG)\n",
    "# ===========\n",
    "tickers = ['SPY US Equity','SPXL US Equity','TLT US Equity','GLD US Equity','DBC US Equity','UUP US Equity','BTAL US Equity']\n",
    "prices_raw = blp.bdh(tickers=tickers, flds='PX_LAST', start_date=START, end_date=END)\n",
    "prices = extract_field(prices_raw, 'PX_LAST')\n",
    "\n",
    "vix_raw = blp.bdh(tickers='VIX Index', flds='PX_LAST', start_date=START, end_date=END)\n",
    "vix = extract_field(vix_raw, 'PX_LAST').squeeze(); vix.name = 'VIX'\n",
    "\n",
    "rename = {\n",
    "    'SPY US Equity':'SPY','SPXL US Equity':'SPXL','TLT US Equity':'TLT','GLD US Equity':'GLD',\n",
    "    'DBC US Equity':'DBC','UUP US Equity':'UUP','BTAL US Equity':'BTAL'\n",
    "}\n",
    "prices = prices.rename(columns={k:v for k,v in rename.items() if k in prices.columns})\n",
    "\n",
    "prices = ensure_dtindex(prices)\n",
    "vix    = ensure_dtindex(vix)\n",
    "\n",
    "data = ensure_dtindex(prices.join(vix, how='inner')).dropna(how='any', subset=['SPY','SPXL','VIX'])\n",
    "data = data.loc[~data.index.duplicated(keep='first')]\n",
    "\n",
    "# ==========\n",
    "# Signal\n",
    "# ==========\n",
    "spy_ret = data['SPY'].pct_change()\n",
    "if ROBUST:\n",
    "    wins = [10,15,20]    # variant described in the post :contentReference[oaicite:5]{index=5}\n",
    "    rv_df = pd.concat({w: realized_vol(spy_ret, w) for w in wins}, axis=1).dropna()\n",
    "    vix_al = data['VIX'].reindex(rv_df.index)\n",
    "    # RV in decimal; VIX in percent\n",
    "    votes = (rv_df.gt((vix_al/100).values.reshape(-1,1))).sum(axis=1)  # 0..3\n",
    "    # Map votes -> SPXL fraction in fallback: 0->1.0, 1->2/3, 2->1/3, 3->0.0 :contentReference[oaicite:6]{index=6}\n",
    "    spxl_frac = votes.map({0:1.0, 1:2/3, 2:1/3, 3:0.0}).astype(float)\n",
    "    signal_daily = spxl_frac\n",
    "else:\n",
    "    rv20 = realized_vol(spy_ret, 20).dropna()  # baseline uses 20d RV vs VIX :contentReference[oaicite:7]{index=7}\n",
    "    vix_al = data['VIX'].reindex(rv20.index)\n",
    "    signal_daily = (rv20 < (vix_al/100)).astype(float)  # 1->SPXL, 0->Cash\n",
    "\n",
    "signal_daily = ensure_dtindex(signal_daily)\n",
    "# Use only info up to T-1: shift the signal forward by 1 business day\n",
    "signal_daily_t1 = signal_daily.shift(1, freq='B')\n",
    "# Sample true Month-End (ME) for month-end rebalance decision\n",
    "signal_me = signal_daily_t1.resample('ME').last()\n",
    "\n",
    "# ======================================\n",
    "# Build monthly target weights (0% cash)\n",
    "# ======================================\n",
    "sleeves = ['TLT','GLD','DBC','UUP','BTAL']\n",
    "# month-ends present in price matrix\n",
    "me_index = data.resample('ME').last().index\n",
    "\n",
    "# non-fallback sleeve weights from your TAA model:\n",
    "w_sleeves = load_base_taa_weights(me_index, sleeves)   # <<--- REPLACE WITH YOUR ACTUAL TAA WEIGHTS for exact replication\n",
    "\n",
    "# assemble portfolio weights\n",
    "cols = ['SPXL'] + sleeves\n",
    "w_filter = pd.DataFrame(0.0, index=me_index, columns=cols)\n",
    "\n",
    "# sleeves (sum to 1 - FALLBACK_WEIGHT)\n",
    "for s in sleeves:\n",
    "    if s in w_filter.columns and s in w_sleeves.columns:\n",
    "        w_filter[s] = w_sleeves[s]\n",
    "\n",
    "# fallback toggles between SPXL and 0%-cash (no cash column; residual sits uninvested)\n",
    "# here we keep the full portfolio sum at 1.0 by allocating fallback entirely to SPXL or to cash (implicitly)\n",
    "w_filter['SPXL'] = FALLBACK_WEIGHT * signal_me.reindex(me_index).fillna(method='ffill').fillna(0.0)\n",
    "\n",
    "# Baseline (no filter): fallback always SPXL\n",
    "w_baseline = w_filter.copy()\n",
    "w_baseline['SPXL'] = FALLBACK_WEIGHT * 1.0\n",
    "\n",
    "# ==============================\n",
    "# Manual backtest (monthly ME)\n",
    "# ==============================\n",
    "price_mat = data[[c for c in cols if c in data.columns]].copy()\n",
    "rets = price_mat.pct_change().fillna(0.0)\n",
    "\n",
    "def run_backtest_me(pr_rets, w_me, fees=FEES, init_nav=INIT_NAV):\n",
    "    # expand monthly weights to daily (piecewise-constant)\n",
    "    w_daily = w_me.reindex(pr_rets.resample('ME').last().index).ffill()\n",
    "    w_daily = w_daily.reindex(pr_rets.index).ffill().fillna(0.0)\n",
    "\n",
    "    # identify rebalance days (true ME present in returns index)\n",
    "    reb_days = w_daily.index.isin(w_me.index)\n",
    "    prev_w = w_daily.shift(1).fillna(0.0)\n",
    "    delta = (w_daily - prev_w).abs()\n",
    "    turnover = delta.sum(axis=1) * reb_days.astype(int)\n",
    "\n",
    "    nav = pd.Series(index=pr_rets.index, dtype=float)\n",
    "    nav.iloc[0] = init_nav\n",
    "    port_ret = pd.Series(0.0, index=pr_rets.index)\n",
    "\n",
    "    # iterate daily; invest weights during day t that were set at end of t-1\n",
    "    for i in range(1, len(pr_rets)):\n",
    "        w_t = w_daily.iloc[i-1]\n",
    "        gross = float(np.dot(w_t.values, pr_rets.iloc[i].values))\n",
    "        fee = fees * turnover.iloc[i]  # proportional cost on rebalance days\n",
    "        net = gross - fee\n",
    "        port_ret.iloc[i] = net\n",
    "        nav.iloc[i] = nav.iloc[i-1] * (1 + net)\n",
    "\n",
    "    # monthly average turnover (on rebalance days)\n",
    "    avg_monthly_to = turnover[reb_days].mean() if turnover[reb_days].size else 0.0\n",
    "    return nav.dropna(), port_ret.dropna(), float(avg_monthly_to)\n",
    "\n",
    "nav_f, ret_f, avg_to_f = run_backtest_me(rets, w_filter, fees=FEES, init_nav=INIT_NAV)\n",
    "nav_b, ret_b, avg_to_b = run_backtest_me(rets, w_baseline, fees=FEES, init_nav=INIT_NAV)\n",
    "\n",
    "# 10% vol-scaled paths for reporting (as in the post)\n",
    "nav_f_10 = vol_target_path(nav_f, TARGET_VOL)\n",
    "nav_b_10 = vol_target_path(nav_b, TARGET_VOL)\n",
    "\n",
    "# ==================\n",
    "# Stats & printout\n",
    "# ==================\n",
    "def pretty(d, title):\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, float):\n",
    "            if 'DD' in k or 'Worst' in k:\n",
    "                print(f\"{k:22s}: {v: .2%}\")\n",
    "            else:\n",
    "                print(f\"{k:22s}: {v: .4f}\")\n",
    "        else:\n",
    "            print(f\"{k:22s}: {v}\")\n",
    "\n",
    "stats_f, _ = stats_panel(nav_f, rf=RF_ANNUAL)\n",
    "stats_b, _ = stats_panel(nav_b, rf=RF_ANNUAL)\n",
    "stats_f['AvgMonthlyTurnover'] = avg_to_f\n",
    "stats_b['AvgMonthlyTurnover'] = avg_to_b\n",
    "\n",
    "stats_f10, _ = stats_panel(nav_f_10, rf=RF_ANNUAL)\n",
    "stats_b10, _ = stats_panel(nav_b_10, rf=RF_ANNUAL)\n",
    "\n",
    "pretty(stats_f,  \"WITH VIX FILTER (raw)\")\n",
    "pretty(stats_b,  \"BASELINE (raw)\")\n",
    "pretty(stats_f10,\"WITH VIX FILTER (10% vol-scaled)\")\n",
    "pretty(stats_b10,\"BASELINE (10% vol-scaled)\")\n",
    "\n",
    "# Save artifacts if desired\n",
    "out = pd.DataFrame({\n",
    "    'NAV_Filter'     : nav_f,\n",
    "    'NAV_NoFilter'   : nav_b,\n",
    "    'NAV_Filter_10%' : nav_f_10,\n",
    "    'NAV_NoFilt_10%' : nav_b_10\n",
    "}).dropna(how='all')\n",
    "out.to_csv('exact_taa_vix_filter_navs.csv')\n",
    "print(\"\\nSaved NAV series -> exact_taa_vix_filter_navs.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52deee01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tajana-DqbFjsyH-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
